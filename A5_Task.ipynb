{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "A5 Task.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNF7azm1ZJ0tBEs7aqWLq95",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/poudel-bibek/Intro-to-AI-Assignments/blob/main/A5_Task.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![inh](https://user-images.githubusercontent.com/96804013/152455353-b69e07d7-d856-4b1a-abd4-bb1c85a22a7d.png)\n"
      ],
      "metadata": {
        "id": "9l5kfEWrMN69"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 5: Long-Short Term Memory (Task)\n",
        "---\n",
        "\n",
        "In this assignment, we will use Long-Short Term Memory (LSTM) ([link](https://en.wikipedia.org/wiki/Long_short-term_memory)) to predict the number of passengers in an airline for the next day given the number of passengers today. The data is represented as a time series.\n",
        "\n",
        "First, let's import necessary libraries.\n",
        "\n",
        "                    \n",
        "                    import math\n",
        "                    import numpy as np\n",
        "                    import pandas as pd\n",
        "                    import matplotlib.pyplot as plt\n",
        "                    from sklearn.preprocessing import MinMaxScaler\n",
        "                    from sklearn.metrics import mean_squared_error\n",
        "                    from sklearn.model_selection import train_test_split\n",
        "\n",
        "                    from tensorflow import keras\n",
        "                    from keras.models import Sequential\n",
        "                    from keras.layers import Dense, LSTM\n"
      ],
      "metadata": {
        "id": "PD8QjV68MN42"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code for downloading the data and visualizing a subset of it is provided below.\n",
        "\n",
        "                    airlines = pd.read_csv('https://github.com/poudel-bibek/Intro-to-AI-Assignments/files/7999363/airline-passengers.csv')\n",
        "                    print(f\"Dataset\\n{airlines.head()}\\n\")\n",
        "\n",
        "                    subset_size = 40 \n",
        "                    subset_months= airlines['Month'][0:subset_size]\n",
        "                    subset_passengers = airlines['Passengers'][0:subset_size]\n",
        "\n",
        "                    fig, ax = plt.subplots(figsize=(14,4), dpi = 80)\n",
        "                    ax.plot(range(len(subset_months)), np.array(subset_passengers), '+', label = \"Passenger count\")\n",
        "                    ax.plot(range(len(subset_months)), np.array(subset_passengers), alpha = 0.5)\n",
        "                    ax.set_xticks(range(len(subset_months))) \n",
        "                    ax.set_xticklabels(subset_months); # ';' prevents displaying auxillary outputs\n",
        "                    plt.xticks(rotation=45);\n",
        "                    ax.legend()\n",
        "\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://user-images.githubusercontent.com/96804013/153318289-1be2e715-5180-48f7-bdb1-9f41b9952b4c.png\")\n",
        "\"/>\n",
        "</p>\n",
        "\n",
        "<p align=\"center\">\n",
        "  <em>Figure 1:Visualization of raw dataset</em>\n",
        "</p>\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MNOA_zcCMN2v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will only be working with the Passengers column. So the dates column can be discarded. \n",
        "\n",
        "Use the code below to:\n",
        "- extract Passengers column \n",
        "- take a peek into it \n",
        "- convert its type \n",
        "- rehsape it \n",
        "- print its shape along with minimum and maximum values in it \n",
        "\n",
        "                    passengers = airlines['Passengers']\n",
        "                    print(f\"Passengers column\\n{passengers.head()}\")\n",
        "\n",
        "                    dataset = passengers.values.astype('float32').reshape(-1,1)\n",
        "                    print(f\"\\nBefore Normalization :\\n shape ={dataset.shape}, max = {np.max(dataset)}, min = {np.min(dataset)}\")"
      ],
      "metadata": {
        "id": "01ddHHxZMN0Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Exercise 1: \n",
        "\n",
        "Normalize the data i.e., the `dataset` variable, using Minmax Scaler ([link](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html)): \n",
        "  - Instantiate a MinMaxScaler() object and make the feature range between 0 and 1\n",
        "  - Use the fit_transform function of MinMaxScaler to scale the dataset\n",
        "  - Print the shape of dataset, max and min values after normalization. \n",
        "  \n",
        "The shape of `(144,1)` means the data looks like this `[[data 0], [data 1], [data 2].... [data 143]]`"
      ],
      "metadata": {
        "id": "3_uTUQk9MNyD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now use the following code to reshape  the dataset to have a shape of `(144,)` and print the shape of the dataset, now we have made the data look like this `[data 0, data 1, data2,.... data 143]`\n",
        "\n",
        "                    dataset = dataset.reshape(-1)\n",
        "                    print(dataset.shape) \n",
        "\n"
      ],
      "metadata": {
        "id": "EKz_O-gTMWiR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The prediction problem is formulated in such a way that we want to look at the passenger number of Day 0 (today) to predict the pessenger number of Day 1 (tomorrow) i.e., there is a difference of 1 day between input feature and output label (`look back = 1`)   \n",
        "\n",
        "- Take a look at the figure below to see how we convert a single sequence of data into supervised data points that contain input feature and a output label.  \n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://user-images.githubusercontent.com/96804013/153277436-42e975b8-043a-4d8a-8752-eea10d93767e.png\")\n",
        "\"/>\n",
        "\n",
        "</p>\n",
        "\n",
        "<p align=\"center\">\n",
        "  <em>Figure 2: Conversion of Sequential data to (x,y) format (Figure Drawn for look back = 1)</em>\n",
        "</p>\n",
        "\n",
        "\n",
        "\n",
        "Now, use the following code to perform this operation for the dataset:  \n",
        "\n",
        "                    def gen_dataset(dset, look_back):\n",
        "                      X = []\n",
        "                      y = []\n",
        "                      for i in range(len(dset)-look_back-1):\n",
        "                        y_value = dset[i + look_back] # output label\n",
        "                        x_value = dset[i : i + look_back] # input feature\n",
        "                        y.append(y_value)\n",
        "                        X.append(x_value)\n",
        "                      \n",
        "                      return np.array(X), np.array(y)\n"
      ],
      "metadata": {
        "id": "vzQorPjIMWgj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, make use of the function that you just wrote:\n",
        "\n",
        "                    look_back = 1\n",
        "                    data_X, data_y = gen_dataset(dataset, look_back)\n",
        "                    print(data_X.shape, data_y.shape)"
      ],
      "metadata": {
        "id": "TzmZfJfZMWeQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Exercise 2\n",
        "- Split the dataset (data_X, data_y) into `train` and `test` sets using `train_test_split` in the ration `70%` train and `30%` test. \n",
        "- Set `shuffle` to `True` and `random_state` to `42`\n",
        "- Store the values in `X_train`, `X_test`, `y_train` and `y_test`.\n",
        "- Print the shapes of `X_train`, `X_test`, `y_train` and `y_test`.\n",
        "\n",
        "Reference ([link](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html))"
      ],
      "metadata": {
        "id": "iDk6MrWQMWbs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Exercise 3\n",
        "\n",
        "\n",
        "Initialize a Sequential model with following code: \n",
        "\n",
        "                  lstm = Sequential()\n",
        "\n",
        "Use `lstm.add()` function to build a LSTM model with the following architecture.\n",
        "\n",
        "- 1st layer: LSTM layer with 100 units; specify `input_shape = (1, look_back)`\n",
        "- 2nd layer (final layer): dense layer with one unit\n",
        "\n",
        "\n",
        "Reference: LSTM ([link](https://keras.io/api/layers/recurrent_layers/lstm/)), Dense ([link](https://keras.io/api/layers/core_layers/dense/))\n",
        "\n",
        "\n",
        "Now compile and train the model:\n",
        "\n",
        "- Compile the model: set `loss` to `mean_squared_error` and `optimizer` to `adam`\n",
        "- Train the model: set `epochs` to 10, `batch_size` to 1, and `verbose` to 2\n",
        "\n",
        "\n",
        "Reference: Compile and fit ([link](https://keras.io/api/models/model_training_apis/))\n"
      ],
      "metadata": {
        "id": "s2LF2MIbMjBZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "- Its time to make predictions on both train and test set and see the error (RMSE) scores. Use the code below: \n",
        "\n",
        "- We have to perform the inverse-normalization operation to the predictions (i.e., convert the data back to the original scale). To do so, we make use of the same scaler that was instantiated and `fitted` earlier.\n",
        "\n",
        "- Since we normalized the output label values as well we want to perform inverse transform operation on them as well. \n",
        "\n",
        "Use the following code: \n",
        "\n",
        "    \n",
        "                    pred_train = lstm.predict(X_train)\n",
        "                    pred_test = lstm.predict(X_test)\n",
        "\n",
        "                    pred_train = scaler.inverse_transform(pred_train)\n",
        "                    pred_test = scaler.inverse_transform(pred_test)\n",
        "\n",
        "                    y_train = scaler.inverse_transform(y_train.reshape(-1,1))\n",
        "                    y_test = scaler.inverse_transform(y_test.reshape(-1,1))\n",
        "              \n",
        "                    train_rmse = math.sqrt(mean_squared_error(y_train, pred_train))\n",
        "                    test_rmse = math.sqrt(mean_squared_error(y_test, pred_test))\n",
        "\n",
        "                    print(f\"Train RMSE = {train_rmse} \\nTest RMSE = {test_rmse}\")"
      ],
      "metadata": {
        "id": "l9mLtACOMi_b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, let's plot a subset of the  model predictions as well as actual values on training set and test set using the following code. \n",
        "        \n",
        "                    def plot(predictions, ground_truths, type = '', plot_x_size = 30):\n",
        "                      predictions = predictions.reshape(-1)[0:plot_x_size]\n",
        "                      ground_truths = ground_truths.reshape(-1)[0: plot_x_size]\n",
        "                      x_axis = range(plot_x_size)\n",
        "\n",
        "                      fig, ax = plt.subplots(figsize=(12,4), dpi = 80)\n",
        "                      ax.plot(x_axis, predictions, alpha = 0.5) \n",
        "                      ax.plot(x_axis, predictions, 'o',label = \"predictions\") \n",
        "                      ax.plot(x_axis, ground_truths, alpha = 0.5) \n",
        "                      ax.plot(x_axis, ground_truths, 'x', label = \"ground truths\") \n",
        "\n",
        "                      ax.set_xticks(x_axis);\n",
        "                      ax.set_xlabel(\"Day number\")\n",
        "                      ax.set_ylabel(\"Passenger Count\")\n",
        "                      ax.set_title(f\"Model performance on a subset of {type} set\")\n",
        "                      ax.legend()\n",
        "                      plt.show()\n",
        "\n",
        "                    plot(pred_train, y_train, 'train')\n",
        "                    plot(pred_test, y_test, 'test')\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://user-images.githubusercontent.com/96804013/153318480-c85d408d-41e0-4470-a815-ed1467e9b0dd.png\")\n",
        "\"/>\n",
        "</p>\n",
        "\n",
        "<p align=\"center\">\n",
        "  <em>Figure 3:Visualization of LSTM predictions on train and test</em>\n",
        "</p>\n"
      ],
      "metadata": {
        "id": "il1NTnz8Mi87"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "uiTH5LP3OB3D"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}