{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "A1 Task.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMamSYaduWp50W4dLVjeJ2f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/poudel-bibek/Intro-to-AI-Assignments/blob/main/A1_Task.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![h_1](https://user-images.githubusercontent.com/96804013/151669059-b10d47f4-66fa-462c-a094-c380b7a277e6.png)"
      ],
      "metadata": {
        "id": "sz8zgNkYsRuV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Basics\n",
        "\n",
        "For this assignment, you will need packages `matplotlib` and `scikit-learn`. Complete the following steps.\n",
        "\n",
        "\n",
        "- Load the diabetdiaes dataset. Set `return_X_y` to `True`, and store the features in variable `diabetes_X` and labels in variable `diabetes_y`.\n",
        "\n",
        "\n",
        "- Check the dimensions of `diabetes_X` and `diabetes_y`.\n",
        "\n",
        "\n",
        "- Visual inspection of a dataset is usually the first thing people do after loading a dataset and also a crucial step prior to the actual learning process. However, here the feature space is high-dimensional which is difficult to plot. Let’s reduce it to 2-dimensional using the following code.\n",
        "\n",
        "\n",
        "    from sklearn import decomposition\n",
        "    pca = decomposition.PCA(n_components=2)\n",
        "    pca.fit(diabetes_X)\n",
        "    X_2d = pca.transform(diabetes_X)\n"
      ],
      "metadata": {
        "id": "KOHStgPeCrJQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, use matplotlib to plot X_2d and produce Figure 1. Remember to provide axis labels also as in the figure.\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://user-images.githubusercontent.com/96804013/151720534-243f0efe-7bae-46cd-80f6-c6963592068d.png\" />\n",
        "</p>\n",
        "\n",
        "<p align=\"center\">\n",
        "  <em>Figure 1: Visual inspection of the dataset</em>\n",
        "</p>\n"
      ],
      "metadata": {
        "id": "C1aJkiPiGqLD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- The default labels of this dataset (i.e., `diabetes_y`) are numerical values not categorical values, which means if we want to do classification instead of regression (this concept will be introduced in later lectures; we don’t need to understand it for this exercise), we need to transform the labels from numerical values to categorical values. This kind of transformation is widely used in modern machine learning projects. So, take the average value of `diabetes_y` and created another label vector `y_binary` which consists of two labels 1 and −1. For elements in `diabetes_y` greater than the average, assign them 1 otherwise −1.\n",
        "\n",
        "\n",
        "- Visualize the dataset again but this time with the positive examples marked as `+` and negative examples marked as `x`. If successful, you should see Figure 2. Remember to provide both axis labels and legends as in the figure. Tip: you may want to use numpy.where to find the indices of the positive and negative examples.\n",
        "\n",
        "\n",
        "- Divide the original dataset into training set, validation set, and test set with the ratio 6:2:2 (note that there is no perfect ratio of the split; 6:2:2 is one of the ratios used by many people; you can also do 7:2:1 for example). Verify your results by checking the dimension of each set. Tip: use `train_test_split` by importing it from `sklearn.model_selection`."
      ],
      "metadata": {
        "id": "hmTmktWmHdix"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Bias-variance Tradeoff\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://user-images.githubusercontent.com/96804013/151720700-525f60a5-a9f4-4496-9c00-a96152d023c2.png\" />\n",
        "</p>\n",
        "\n",
        "<p align=\"center\">\n",
        "  <em>Figure 2: Visual inspection of the dataset with binary labels.</em>\n",
        "</p>"
      ],
      "metadata": {
        "id": "7hARiEwZHwho"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- Write a function called generate_data to produce 1D dataset using the following code:\n",
        "\n",
        "\n",
        "    X = np.array([i*np.pi/180 for i in range(1,150,2)])\n",
        "    y = np.sin(X) + np.random.normal(0,0.15,len(X))\n",
        "\n",
        "\n",
        "  Split `X` and `y` into training set that contains 50 samples and test set that contains 25 samples. Note: if you want repeatable experiments then you need to fix the random seed.\n",
        "\n",
        "\n",
        "- Use the following code to train a linear regression model. Although we have not covered linear regression yet, we can proceed this exercise without its the formal definition.\n",
        "\n",
        "\n",
        "    from sklearn.linear_model import LinearRegression\n",
        "    lr = LinearRegression()\n",
        "    lr.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "  The coefficients and intercept can be accessed as `lr.coef_` and `lr.intercept_`. Use them to compute the training error and test error. Plot the fitted line along with the training set and test set as in Figure 1 (you may not have the same plot because the dataset is generated randomly)."
      ],
      "metadata": {
        "id": "ml2LOoznIK-R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"center\">\n",
        "  <img src=\"https://user-images.githubusercontent.com/96804013/151720757-4ea26cc2-17c0-45fb-8273-5024a242ebea.png\" />\n",
        "</p>\n",
        "\n",
        "<p align=\"center\">\n",
        "  <em>Figure 3: Ordinal linear regression with the training set and test set. </em>\n",
        "</p>\n",
        "\n",
        "The objective function of ordinal linear regression is just the summation of the squared errors between predicted labels and the true labels:\n",
        "\n",
        "$$J(\\theta,\\theta_0) = \\sum_{i=1}^{n}\\left(\\left(\\theta \\cdot x^{(i)}+\\theta_0\\right) - y^{(i)}\\right)^2$$\n",
        "\n",
        "One type of linear regression, called ridge regression, has its objective function very similar to the objective function of linear classification:\n",
        "\n",
        "$$J(\\theta,\\theta_0) = \\frac{1}{n}\\sum_{i=1}^{n}\\left(\\left(\\theta \\cdot x^{(i)}+\\theta_0\\right) - y^{(i)}\\right)^2 + \\alpha\\left(\\theta^2 + \\theta_0^2\\right)$$\n",
        "\n",
        "\n",
        "which is the objective function of the ordinal linear regression plus the regularization term. Fit a ridge regression using the following code:\n",
        "\n",
        "\n",
        "    from sklearn.linear_model import Ridge\n",
        "    rr = Ridge(alpha=10)\n",
        "    rr.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "Use the coefficients `rr.coef_` and intercept `rr.intercept_` to compute the training error and test error. Plot the fitted line along with the training set and test set as before. Do this for alpha value 1, 100, and 1000, respectively. What are the differences? What causes the differences? And when we will have the same line as the ordinal linear regression?\n",
        "\n"
      ],
      "metadata": {
        "id": "BdCUqPk-IUrX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "BNwSOyvTGe9A"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}